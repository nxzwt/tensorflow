import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("MNIST_data/",one_hot=True)#import matplotlib#import pylabimport datetimetf.reset_default_graph()#定义占位符x = tf.placeholder(tf.float32,[None,784])y = tf.placeholder(tf.float32,[None,10])W = tf.Variable(tf.random_normal(([784,10])))b = tf.Variable(tf.zeros([10]))pred = tf.nn.softmax(tf.matmul(x,W) + b)#损失函数cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),reduction_indices=1))#定义参数learning_rate = 0.01#使用梯度下降优化optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)training_epochs = 100batch_size = 100display_step = 1#存储训练模型saver = tf.train.Saver()model_path = "log1/521model.ckpt"tf.reset_default_graph()#定义占位符x = tf.placeholder(tf.float32,[None,784])y = tf.placeholder(tf.float32,[None,10])W = tf.Variable(tf.random_normal(([784,10])))b = tf.Variable(tf.zeros([10]))pred = tf.nn.softmax(tf.matmul(x,W) + b)#损失函数cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),reduction_indices=1))#定义参数learning_rate = 0.01#使用梯度下降优化optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)training_epochs = 100batch_size = 100display_step = 1#存储训练模型saver = tf.train.Saver()model_path = "log/521model.ckpt"#启动sessionstarttime = datetime.datetime.now()with tf.Session() as sess:    sess.run(tf.global_variables_initializer())        #启动循环开始训练    for epoch in range(training_epochs):        avg_cost = 0.0        total_batch = int(mnist.train.num_examples/batch_size)        #循环所有数据集        for i  in range(total_batch):            batch_xs,batch_ys = mnist.train.next_batch(batch_size)            #运行优化器            _,c = sess.run([optimizer,cost],feed_dict = {x:batch_xs,y:batch_ys})                        #计算平均cost            avg_cost += c / total_batch        #显示训练中的详细信息        if (epoch + 1 ) % display_step == 0 :            print("Epoch:",'%0.4d' % (epoch + 1),"cost=","{:.9f}".format(avg_cost))                print("Finished!")    #测试model    correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))    #计算准确率    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))    print("Accuracy:",accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))    #保存模型    save_path = saver.save(sess,model_path)    print("Model saved in file: %s" % save_path)endtime = datetime.datetime.now()print("traning time: ",(endtime - starttime))print("Starting 2nd session...")n = 20with tf.Session() as sess:    #初始化变量    sess.run(tf.global_variables_initializer())    #恢复模型变量    saver.restore(sess,model_path)        #测试model    correct_predoctopm = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))    #计算准确率    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))    print("Accuracy:",accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))        output = tf.argmax(pred,1)    batch_xs,batch_ys = mnist.train.next_batch(n)    outputval,predv = sess.run([output,pred],feed_dict={x:batch_xs})    #print(outputval,predv,batch_ys)    #print("No.","result","               actucal        ")    for i in range(n):        if(batch_ys[i][outputval[i]])  == 1:            result = "o k"        else:            result = "err"        print("No.",i+1,"-->",outputval[i],"-->",batch_ys[i],"-->",result)
